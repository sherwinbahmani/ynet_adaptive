{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 2022_01_29_02_20_06 has started\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import yaml\n",
    "from model import YNet\n",
    "from datetime import datetime\n",
    "from utils.preprocessing import load_raw_dataset\n",
    "import time\n",
    "\n",
    "tic = time.time()\n",
    "\n",
    "FOLDERNAME = './'\n",
    "time_stamp = datetime.now().strftime('%Y_%m_%d_%H_%M_%S')\n",
    "CHECKPOINT = None # FOLDERNAME + 'pretrained_models/2022_01_27_23_58_00_weights.pt' # None means no checkpoint will be used to fine-tune\n",
    "CONFIG_FILE_PATH = 'config/sdd_raw_train.yaml'  # yaml config file containing all the hyperparameters\n",
    "EXPERIMENT_NAME = time_stamp  # arbitrary name for this experiment\n",
    "DATASET_NAME = 'sdd'\n",
    "SDD_RAW_PATH = FOLDERNAME + \"data/sdd_raw\"\n",
    "with open(CONFIG_FILE_PATH) as file:\n",
    "    params = yaml.load(file, Loader=yaml.FullLoader)\n",
    "print(f\"Experiment {EXPERIMENT_NAME} has started\")\n",
    "\n",
    "if params['use_raw_data']:\n",
    "    TRAIN_IMAGE_PATH = FOLDERNAME + 'data/sdd_raw/annotations'\n",
    "    TEST_IMAGE_PATH = FOLDERNAME + 'data/sdd_raw/annotations'\n",
    "else:\n",
    "    TEST_DATA_PATH = FOLDERNAME + 'data/SDD/test_trajnet.pkl'\n",
    "    TEST_IMAGE_PATH = FOLDERNAME + 'data/SDD/test'  # only needed for YNet, PECNet ignores this value\n",
    "params['segmentation_model_fp'] = FOLDERNAME + 'ynet_additional_files/segmentation_models/SDD_segmentation.pth'\n",
    "OBS_LEN = 8  # in timesteps\n",
    "PRED_LEN = 12  # in timesteps\n",
    "NUM_GOALS = 20  # K_e\n",
    "NUM_TRAJ = 1  # K_a\n",
    "ROUNDS = 1  # Y-net is stochastic. How often to evaluate the whole dataset\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2662 agents for each training class, 518 agents for test class\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if params['use_raw_data']:\n",
    "    train_data, val_data = load_raw_dataset(path=SDD_RAW_PATH, step=params['step'],\n",
    "                                  window_size=params['min_num_steps_seq'], stride=params['filter_stride'],\n",
    "                                  train_labels=params['train_labels'], test_labels=params['test_labels'],\n",
    "                                  test_per=params['test_per'], max_train_agents=params['max_train_agents'],\n",
    "                                  train_set_ratio=params['train_set_ratio'], test_on_train=params['test_on_train'],\n",
    "                                  num_train_agents=params['num_train_agents'], num_test_agents=params['num_test_agents'],\n",
    "                                  random_train_test=params['random_train_test_split'])\n",
    "else:\n",
    "\ttrain_data = pd.read_pickle(TRAIN_IMAGE_PATH)\n",
    "\tval_data = pd.read_pickle(TEST_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonas/miniconda3/envs/rebut/lib/python3.8/site-packages/torch/serialization.py:671: SourceChangeWarning: source code of class 'segmentation_models_pytorch.encoders.resnet.ResNetEncoder' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/jonas/miniconda3/envs/rebut/lib/python3.8/site-packages/torch/serialization.py:671: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/jonas/miniconda3/envs/rebut/lib/python3.8/site-packages/torch/serialization.py:671: SourceChangeWarning: source code of class 'torch.nn.modules.batchnorm.BatchNorm2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/jonas/miniconda3/envs/rebut/lib/python3.8/site-packages/torch/serialization.py:671: SourceChangeWarning: source code of class 'torch.nn.modules.activation.ReLU' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/jonas/miniconda3/envs/rebut/lib/python3.8/site-packages/torch/serialization.py:671: SourceChangeWarning: source code of class 'torch.nn.modules.pooling.MaxPool2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/jonas/miniconda3/envs/rebut/lib/python3.8/site-packages/torch/serialization.py:671: SourceChangeWarning: source code of class 'torch.nn.modules.container.Sequential' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/jonas/miniconda3/envs/rebut/lib/python3.8/site-packages/torch/serialization.py:671: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Identity' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/jonas/miniconda3/envs/rebut/lib/python3.8/site-packages/torch/serialization.py:671: SourceChangeWarning: source code of class 'torch.nn.modules.container.ModuleList' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/jonas/miniconda3/envs/rebut/lib/python3.8/site-packages/torch/serialization.py:671: SourceChangeWarning: source code of class 'segmentation_models_pytorch.base.modules.Conv2dReLU' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/jonas/miniconda3/envs/rebut/lib/python3.8/site-packages/torch/serialization.py:671: SourceChangeWarning: source code of class 'segmentation_models_pytorch.base.modules.Activation' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/jonas/miniconda3/envs/rebut/lib/python3.8/site-packages/torch/serialization.py:671: SourceChangeWarning: source code of class 'torch.nn.modules.activation.Softmax' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocess data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prepare Dataset: 100%|██████████| 424/424 [00:00<00:00, 1469.45it/s]\n",
      "/home/jonas/vita_epfl_causal/ynet/utils/dataloader.py:37: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(trajectories), meta, scene_list\n",
      "Prepare Dataset: 100%|██████████| 184/184 [00:00<00:00, 1338.00it/s]\n",
      "Prepare Dataset: 100%|██████████| 464/464 [00:00<00:00, 1442.62it/s]\n",
      "Prepare Dataset: 100%|██████████| 15/15 [00:00<00:00, 1376.29it/s]\n",
      "Prepare Dataset: 100%|██████████| 17/17 [00:00<00:00, 1426.92it/s]\n",
      "Prepare Dataset: 100%|██████████| 7/7 [00:00<00:00, 1255.40it/s]\n",
      "Epoch:   0%|          | 0/300 [00:00<?, ?it/s]/home/jonas/miniconda3/envs/rebut/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "Epoch:   0%|          | 0/300 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "torch.cat(): Sizes of tensors must match except in dimension 1. Got 32 and 31 in dimension 2 (The offending index is 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/jonas/vita_epfl_causal/ynet/notebook.ipynb Cell 4'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bvita/home/jonas/vita_epfl_causal/ynet/notebook.ipynb#ch0000003vscode-remote?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m YNet(obs_len\u001b[39m=\u001b[39mOBS_LEN, pred_len\u001b[39m=\u001b[39mPRED_LEN, params\u001b[39m=\u001b[39mparams)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bvita/home/jonas/vita_epfl_causal/ynet/notebook.ipynb#ch0000003vscode-remote?line=1'>2</a>\u001b[0m \u001b[39mif\u001b[39;00m CHECKPOINT: model\u001b[39m.\u001b[39mload(CHECKPOINT)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bvita/home/jonas/vita_epfl_causal/ynet/notebook.ipynb#ch0000003vscode-remote?line=2'>3</a>\u001b[0m model\u001b[39m.\u001b[39;49mtrain_style_enc(train_data, val_data, params, train_image_path\u001b[39m=\u001b[39;49mTRAIN_IMAGE_PATH, val_image_path\u001b[39m=\u001b[39;49mTEST_IMAGE_PATH,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bvita/home/jonas/vita_epfl_causal/ynet/notebook.ipynb#ch0000003vscode-remote?line=3'>4</a>\u001b[0m \t\t\t\texperiment_name\u001b[39m=\u001b[39;49mEXPERIMENT_NAME, batch_size\u001b[39m=\u001b[39;49mBATCH_SIZE, num_goals\u001b[39m=\u001b[39;49mNUM_GOALS, num_traj\u001b[39m=\u001b[39;49mNUM_TRAJ, \n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bvita/home/jonas/vita_epfl_causal/ynet/notebook.ipynb#ch0000003vscode-remote?line=4'>5</a>\u001b[0m \t\t\t\tdevice\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, dataset_name\u001b[39m=\u001b[39;49mDATASET_NAME, use_raw_data\u001b[39m=\u001b[39;49mparams[\u001b[39m'\u001b[39;49m\u001b[39muse_raw_data\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bvita/home/jonas/vita_epfl_causal/ynet/notebook.ipynb#ch0000003vscode-remote?line=6'>7</a>\u001b[0m toc \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bvita/home/jonas/vita_epfl_causal/ynet/notebook.ipynb#ch0000003vscode-remote?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(time\u001b[39m.\u001b[39mstrftime(\u001b[39m\"\u001b[39m\u001b[39m%\u001b[39m\u001b[39mHh\u001b[39m\u001b[39m%\u001b[39m\u001b[39mMm\u001b[39m\u001b[39m%\u001b[39m\u001b[39mSs\u001b[39m\u001b[39m\"\u001b[39m, time\u001b[39m.\u001b[39mgmtime(toc \u001b[39m-\u001b[39m tic)))\n",
      "File \u001b[0;32m~/vita_epfl_causal/ynet/model.py:675\u001b[0m, in \u001b[0;36mYNet.train_style_enc\u001b[0;34m(self, train_data, val_data, params, train_image_path, val_image_path, experiment_name, batch_size, num_goals, num_traj, device, dataset_name, use_raw_data)\u001b[0m\n\u001b[1;32m    <a href='file:///~/vita_epfl_causal/ynet/model.py?line=672'>673</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mStart training\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    <a href='file:///~/vita_epfl_causal/ynet/model.py?line=673'>674</a>\u001b[0m \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(params[\u001b[39m'\u001b[39m\u001b[39mnum_epochs\u001b[39m\u001b[39m'\u001b[39m]), desc\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEpoch\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m--> <a href='file:///~/vita_epfl_causal/ynet/model.py?line=674'>675</a>\u001b[0m \ttrain_loss, train_accuracy \u001b[39m=\u001b[39m train_style_enc(model, train_loaders, train_images, e, obs_len, pred_len,\n\u001b[1;32m    <a href='file:///~/vita_epfl_causal/ynet/model.py?line=675'>676</a>\u001b[0m \t\t\t\t\t\t\t\t\t\t\t batch_size, params, gt_template, device,\n\u001b[1;32m    <a href='file:///~/vita_epfl_causal/ynet/model.py?line=676'>677</a>\u001b[0m \t\t\t\t\t\t\t\t\t\t\t input_template, optimizer, criterion, dataset_name, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhomo_mat)\n\u001b[1;32m    <a href='file:///~/vita_epfl_causal/ynet/model.py?line=678'>679</a>\u001b[0m \t\u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mTrain loss: \u001b[39m\u001b[39m{\u001b[39;00mtrain_loss\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mTrain style accuracy: \u001b[39m\u001b[39m{\u001b[39;00mtrain_accuracy\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m    <a href='file:///~/vita_epfl_causal/ynet/model.py?line=680'>681</a>\u001b[0m \ttest_loss, test_accuracy \u001b[39m=\u001b[39m evaluate_style(model, val_loaders, val_images, e, obs_len, pred_len,\n\u001b[1;32m    <a href='file:///~/vita_epfl_causal/ynet/model.py?line=681'>682</a>\u001b[0m \t\t\t\t\t\t\t\t\t\t\t batch_size, params, gt_template, device,\n\u001b[1;32m    <a href='file:///~/vita_epfl_causal/ynet/model.py?line=682'>683</a>\u001b[0m \t\t\t\t\t\t\t\t\t\t\t input_template, optimizer, criterion, dataset_name, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhomo_mat)\n",
      "File \u001b[0;32m~/vita_epfl_causal/ynet/train.py:157\u001b[0m, in \u001b[0;36mtrain_style_enc\u001b[0;34m(model, train_loaders, train_images, e, obs_len, pred_len, batch_size, params, gt_template, device, input_template, optimizer, criterion, dataset_name, homo_mat, style_only)\u001b[0m\n\u001b[1;32m    <a href='file:///~/vita_epfl_causal/ynet/train.py?line=154'>155</a>\u001b[0m \t\tmodel\u001b[39m.\u001b[39meval()\n\u001b[1;32m    <a href='file:///~/vita_epfl_causal/ynet/train.py?line=155'>156</a>\u001b[0m \t\tscene_image \u001b[39m=\u001b[39m train_images[scene]\u001b[39m.\u001b[39mto(device)\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\n\u001b[0;32m--> <a href='file:///~/vita_epfl_causal/ynet/train.py?line=156'>157</a>\u001b[0m \t\tscene_images\u001b[39m.\u001b[39mappend(model\u001b[39m.\u001b[39;49msegmentation(scene_image))\n\u001b[1;32m    <a href='file:///~/vita_epfl_causal/ynet/train.py?line=157'>158</a>\u001b[0m \t\tmodel\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m    <a href='file:///~/vita_epfl_causal/ynet/train.py?line=159'>160</a>\u001b[0m len_min_trajectories \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m([\u001b[39mlen\u001b[39m(traj) \u001b[39mfor\u001b[39;00m traj \u001b[39min\u001b[39;00m trajectories])\n",
      "File \u001b[0;32m~/vita_epfl_causal/ynet/model.py:264\u001b[0m, in \u001b[0;36mYNetTorch.segmentation\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m    <a href='file:///~/vita_epfl_causal/ynet/model.py?line=262'>263</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msegmentation\u001b[39m(\u001b[39mself\u001b[39m, image):\n\u001b[0;32m--> <a href='file:///~/vita_epfl_causal/ynet/model.py?line=263'>264</a>\u001b[0m \t\u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msemantic_segmentation(image)\n",
      "File \u001b[0;32m~/miniconda3/envs/rebut/lib/python3.8/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///~/miniconda3/envs/rebut/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1046'>1047</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/miniconda3/envs/rebut/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1047'>1048</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/miniconda3/envs/rebut/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1048'>1049</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///~/miniconda3/envs/rebut/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1049'>1050</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///~/miniconda3/envs/rebut/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1050'>1051</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///~/miniconda3/envs/rebut/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1051'>1052</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/miniconda3/envs/rebut/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1052'>1053</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/rebut/lib/python3.8/site-packages/segmentation_models_pytorch/base/model.py:16\u001b[0m, in \u001b[0;36mSegmentationModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='file:///~/miniconda3/envs/rebut/lib/python3.8/site-packages/segmentation_models_pytorch/base/model.py?line=13'>14</a>\u001b[0m \u001b[39m\"\"\"Sequentially pass `x` trough model`s encoder, decoder and heads\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='file:///~/miniconda3/envs/rebut/lib/python3.8/site-packages/segmentation_models_pytorch/base/model.py?line=14'>15</a>\u001b[0m features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder(x)\n\u001b[0;32m---> <a href='file:///~/miniconda3/envs/rebut/lib/python3.8/site-packages/segmentation_models_pytorch/base/model.py?line=15'>16</a>\u001b[0m decoder_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecoder(\u001b[39m*\u001b[39;49mfeatures)\n\u001b[1;32m     <a href='file:///~/miniconda3/envs/rebut/lib/python3.8/site-packages/segmentation_models_pytorch/base/model.py?line=17'>18</a>\u001b[0m masks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msegmentation_head(decoder_output)\n\u001b[1;32m     <a href='file:///~/miniconda3/envs/rebut/lib/python3.8/site-packages/segmentation_models_pytorch/base/model.py?line=19'>20</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclassification_head \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/rebut/lib/python3.8/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///~/miniconda3/envs/rebut/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1046'>1047</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/miniconda3/envs/rebut/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1047'>1048</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/miniconda3/envs/rebut/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1048'>1049</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///~/miniconda3/envs/rebut/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1049'>1050</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///~/miniconda3/envs/rebut/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1050'>1051</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///~/miniconda3/envs/rebut/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1051'>1052</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/miniconda3/envs/rebut/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1052'>1053</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/rebut/lib/python3.8/site-packages/segmentation_models_pytorch/unet/decoder.py:119\u001b[0m, in \u001b[0;36mUnetDecoder.forward\u001b[0;34m(self, *features)\u001b[0m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/rebut/lib/python3.8/site-packages/segmentation_models_pytorch/unet/decoder.py?line=116'>117</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, decoder_block \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocks):\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/rebut/lib/python3.8/site-packages/segmentation_models_pytorch/unet/decoder.py?line=117'>118</a>\u001b[0m     skip \u001b[39m=\u001b[39m skips[i] \u001b[39mif\u001b[39;00m i \u001b[39m<\u001b[39m \u001b[39mlen\u001b[39m(skips) \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> <a href='file:///~/miniconda3/envs/rebut/lib/python3.8/site-packages/segmentation_models_pytorch/unet/decoder.py?line=118'>119</a>\u001b[0m     x \u001b[39m=\u001b[39m decoder_block(x, skip)\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/rebut/lib/python3.8/site-packages/segmentation_models_pytorch/unet/decoder.py?line=120'>121</a>\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/miniconda3/envs/rebut/lib/python3.8/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///~/miniconda3/envs/rebut/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1046'>1047</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/miniconda3/envs/rebut/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1047'>1048</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/miniconda3/envs/rebut/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1048'>1049</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///~/miniconda3/envs/rebut/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1049'>1050</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///~/miniconda3/envs/rebut/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1050'>1051</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///~/miniconda3/envs/rebut/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1051'>1052</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/miniconda3/envs/rebut/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1052'>1053</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/rebut/lib/python3.8/site-packages/segmentation_models_pytorch/unet/decoder.py:38\u001b[0m, in \u001b[0;36mDecoderBlock.forward\u001b[0;34m(self, x, skip)\u001b[0m\n\u001b[1;32m     <a href='file:///~/miniconda3/envs/rebut/lib/python3.8/site-packages/segmentation_models_pytorch/unet/decoder.py?line=35'>36</a>\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39minterpolate(x, scale_factor\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mnearest\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='file:///~/miniconda3/envs/rebut/lib/python3.8/site-packages/segmentation_models_pytorch/unet/decoder.py?line=36'>37</a>\u001b[0m \u001b[39mif\u001b[39;00m skip \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> <a href='file:///~/miniconda3/envs/rebut/lib/python3.8/site-packages/segmentation_models_pytorch/unet/decoder.py?line=37'>38</a>\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mcat([x, skip], dim\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     <a href='file:///~/miniconda3/envs/rebut/lib/python3.8/site-packages/segmentation_models_pytorch/unet/decoder.py?line=38'>39</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattention1(x)\n\u001b[1;32m     <a href='file:///~/miniconda3/envs/rebut/lib/python3.8/site-packages/segmentation_models_pytorch/unet/decoder.py?line=39'>40</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv1(x)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: torch.cat(): Sizes of tensors must match except in dimension 1. Got 32 and 31 in dimension 2 (The offending index is 1)"
     ]
    }
   ],
   "source": [
    "model = YNet(obs_len=OBS_LEN, pred_len=PRED_LEN, params=params)\n",
    "if CHECKPOINT: model.load(CHECKPOINT)\n",
    "model.train_style_enc(train_data, val_data, params, train_image_path=TRAIN_IMAGE_PATH, val_image_path=TEST_IMAGE_PATH,\n",
    "\t\t\t\texperiment_name=EXPERIMENT_NAME, batch_size=BATCH_SIZE, num_goals=NUM_GOALS, num_traj=NUM_TRAJ, \n",
    "\t\t\t\tdevice='cpu', dataset_name=DATASET_NAME, use_raw_data=params['use_raw_data'])\n",
    "\n",
    "toc = time.time()\n",
    "print(time.strftime(\"%Hh%Mm%Ss\", time.gmtime(toc - tic)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "470c3a1d38d3b28f01b81a0263a6341bcba31d315455af62dbe054a0b795934c"
  },
  "kernelspec": {
   "display_name": "Python 3.7.1 64-bit (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
